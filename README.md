# Facial Emotion Recognition using CNN

##  Overview
This project implements a **Facial Emotion Recognition** system using **Convolutional Neural Networks (CNNs)**. The model classifies human facial expressions into different emotions such as **Happy, Sad, Angry, Surprised, Neutral, Fear, and Disgust**.

## ğŸ“‚ Project Structure
```
facial_emotion_recognition/
â”‚-- data/                   # Directory for dataset (train/test images)
â”‚-- models/                 # Saved trained models
â”‚-- scripts/                # Source code for training and evaluation
â”‚   â”‚-- train.py            # Training script
â”‚   â”‚-- evaluate.py         # Model evaluation
â”‚   â”‚-- predict.py          # Real-time emotion detection (optional)
â”‚-- requirements.txt        # List of dependencies
â”‚-- README.md               # Project documentation
â”‚-- app.py                  # Streamlit web app for emotion detection
```

## ğŸ“Š Dataset
The **FER2013 dataset** is used for training and evaluation. It comprises **35,887 grayscale images (48x48 pixels)** of human faces, labeled into seven emotion classes:

- **Angry** 
- **Disgust** 
- **Fear** 
- **Happy** 
- **Neutral**
- **Sad** 
- **Surprise** 

### ğŸ”¹ Dataset Structure
```
data/
â”‚-- train/
â”‚   â”‚-- angry/
â”‚   â”‚-- disgust/
â”‚   â”‚-- fear/
â”‚   â”‚-- happy/
â”‚   â”‚-- neutral/
â”‚   â”‚-- sad/
â”‚   â”‚-- surprise/
â”‚-- test/
```

### ğŸ”¹ Download the Dataset
Run the following command to download the dataset from Kaggle:
```sh
kaggle datasets download -d msambare/fer2013
```
Then extract it:
```sh
unzip fer2013.zip -d data/
```

## âš™ï¸ Installation
### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/4yamneBH/facial-emotion-recognition.git
cd facial-emotion-recognition
```
### 2ï¸âƒ£ Create a Virtual Environment
```sh
python -m venv env
# On Windows:
env\Scripts\activate  
# On macOS/Linux:
source env/bin/activate
```
### 3ï¸âƒ£ Install Dependencies
```sh
pip install -r requirements.txt
```

##  Model Architecture
The project implements a **VGG16-based model**, fine-tuned for emotion classification.

### ğŸ”¹ Key Features:
âœ” Pre-trained **VGG16 backbone** for feature extraction  
âœ” Additional **Dense layers** for classification  
âœ” **Dropout layers** to prevent overfitting  
âœ” Optimized with **Adam optimizer** and **categorical cross-entropy loss**  

### ğŸ”¹ Model Summary:
```python
model = tf.keras.models.Sequential([
    vgg16_model,  # Pre-trained VGG16 model
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(7, activation='softmax')  # 7 emotion classes
])
```

##  Training the Model
Run the following command to train the model:
```sh
python scripts/train.py
```

## ğŸ“ˆ Results & Performance
| Model              | Validation Accuracy | Training Accuracy |
|--------------------|--------------------|-------------------|
| Custom CNN        | ~38%               | ~50%              |
| VGG16 (Fine-tuned)| ~70%               | ~85%              |

ğŸ”¹ **VGG16 significantly outperformed the custom CNN** due to its powerful feature extraction capabilities.  
ğŸ”¹ **Training loss and validation loss stabilized**, reducing overfitting.

##  Real-Time Emotion Detection
To use the model for **real-time emotion recognition** via webcam, run:
```sh
python scripts/predict.py
```
![preview](./exp.png)
## ğŸŒ Web Application
A **Streamlit web app** is included for easy emotion recognition using uploaded images.
### Run the app using:
```sh
streamlit run app.py
```
### Features:
- Upload an image and get emotion predictions.
- Displays **confidence scores** for each emotion class.

## ğŸ“œ License
This project is open-source and available under the **MIT License**.

---
ğŸ’¡ **Contributions & Feedback** are welcome! Feel free to open an issue or submit a pull request. 

